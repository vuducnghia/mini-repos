import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Input, Dropout, MaxPooling2D, Conv2D, GRU
from tensorflow.keras.models import Model


def maxpooling(base_model):
    model = Sequential(name='vgg16')
    for layer in base_model.layers[:-1]:
        if 'pool' in layer.name:
            pooling_layer = MaxPooling2D(pool_size=(2, 2), name=layer.name)
            model.add(pooling_layer)
        else:
            model.add(layer)
    return model


class Encoder(tf.keras.Model):
    layers = [
        Conv2D(32, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform'),
        Conv2D(64, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform'),
        Conv2D(64, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform'),
        # BatchNormalization(),
        MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),

        Conv2D(128, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform'),
        Conv2D(128, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform'),
        Conv2D(128, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform'),
        MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),

        Conv2D(256, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform'),
        Conv2D(256, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform'),
        Conv2D(256, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform'),
        # BatchNormalization(),
        Conv2D(256, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform'),
        # MaxPooling2D(pool_size=(2, 1), strides=(2, 1), padding='valid'),

        Conv2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform'),
        # BatchNormalization(),
        Conv2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform'),
        # MaxPooling2D(pool_size=(2, 1), strides=(2, 1), padding='valid'),

        Conv2D(512, (2, 2), padding='valid', activation='relu', kernel_initializer='he_uniform'),
        # BatchNormalization(),
        Dropout(rate=0.5)
    ]
    def __init__(self, encode_units, fine_tune=False):
        super().__init__()
        self.base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False)
        self.cnn = maxpooling(self.base_model)
        if fine_tune:
            self.cnn.trainable = True
        else:
            self.cnn.trainable = False
        # self.cnn = Sequential(self.layers)
        self.encode_units = encode_units
        self.bigru = GRU(units=self.encode_units, return_sequences=True, return_state=True,
                         recurrent_initializer='glorot_uniform')

    def call(self, x):
        x = self.cnn(x)  # (bs, 2, 20,512)
        x = tf.reshape(x, shape=(-1, x.shape[1]* x.shape[2],x.shape[3]))    #(bs, 40, 512)
        output, state = self.bigru(inputs=x)    #(bs, 40, 256)

        return output, state


class BahdanauAttention(tf.keras.layers.Layer):
    def __init__(self, units):
        super().__init__()
        self.W1 = tf.keras.layers.Dense(units)
        self.W2 = tf.keras.layers.Dense(units)
        self.V = tf.keras.layers.Dense(1)

    # hidden: hidden state is generated by last element of sequence
    # features: sequence hidden state
    def call(self, hidden, features):
        # hidden hidden state shape == (batch_size, hidden size)
        # hidden_with_time_axis shape == (batch_size, 1, hidden size)
        # featuress shape == (batch_size, max_len_word, hidden size)
        # we are doing this to broadcast addition along the time axis to calculate the score
        hidden_with_time_axis = tf.expand_dims(hidden, 1)

        # score = FC(tanh(FC(EO) + FC(H)))      #EO = Encoder output
        score = self.V(tf.nn.tanh(self.W1(hidden_with_time_axis) + self.W2(features)))  # shape: (bz, max_len_word, 1)

        # attention weights = softmax(score, axis = 1)
        attention_weight = tf.nn.softmax(score, axis=1)  # shape: (bz, max_len_word, 1)

        # context vector = sum(attention weights * EO, axis = 1)
        context_vector = attention_weight * features  # shape: (bz, max_len_word, hidden size)
        context_vector = tf.reduce_sum(context_vector, axis=1)  # shape: (bz, hidden size)

        return context_vector, attention_weight


class Decoder(tf.keras.Model):
    def __init__(self, vocab_size, embedding_dim, decode_units):
        super().__init__()
        self.decode_units = decode_units
        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)
        self.gru = tf.keras.layers.GRU(units=self.decode_units, return_sequences=True, return_state=True,
                                       recurrent_initializer='glorot_uniform')
        self.fc = tf.keras.layers.Dense(vocab_size)

        # used for attention
        self.attention = BahdanauAttention(self.decode_units)

    def call(self, x, hidden, features):
        # features shape == (batch_size, max_length, hidden_size)
        # context_vector shape: (bz, hidden size)
        context_vector, attention_weight = self.attention(hidden, features)

        # x shape before == (batch_size, 1)
        # x shape after passing through embedding == (batch_size, 1, embedding_dim)
        x = self.embedding(x)  # (bs, 1, 256)

        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)
        x = tf.concat([tf.expand_dims(context_vector, axis=1), x], axis=-1)

        # passing the concatenated vector to the GRU
        output, state = self.gru(x)  # shape output: (bz, 1, decode_units)

        # output shape == (batch_size * 1, decode_units)
        output = tf.reshape(output, shape=(-1, output.shape[2]))

        # output shape == (batch_size, vocab_size)
        x = self.fc(output)

        return x, state

    def reset_state(self, batch_size):
        return tf.zeros((batch_size, self.decode_units))


class AttentionOCR:
    def __init__(self, image_width, image_height, vocab_size, encode_units, decode_units, embedding_dim,
                 max_txt_length, fine_tune):
        self.max_txt_length = max_txt_length
        self.encoder = Encoder(encode_units=encode_units, fine_tune=fine_tune)
        self.decoder = Decoder(vocab_size=vocab_size, embedding_dim=embedding_dim, decode_units=decode_units)

        self.encoder_input = Input((image_height, image_width, 3), name='encoder_input')
        self.decoder_input = Input(1, name='decoder_input')
        self.hidden = Input(decode_units, name='hidden')

    def build_model_train(self):
        features, _ = self.encoder(self.encoder_input)
        logits, state = self.decoder(self.decoder_input, self.hidden, features)

        return Model([self.encoder_input, self.decoder_input, self.hidden], [logits, state])

    def build_model_inference(self):
        predictions = []
        features, _ = self.encoder(self.encoder_input)
        hidden = self.hidden
        for i in range(self.max_txt_length):
            predict, hidden = self.decoder(self.decoder_input, hidden, features)  # predict shape (bs, vocab_size)
            predictions.append(predict)  # (max_length_text, bs, vocab_size)

        predictions = tf.cast(predictions, dtype=tf.float64)

        return Model(inputs=[self.encoder_input, self.decoder_input, self.hidden], outputs=predictions)
